% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spatialized_classification.R
\name{spatialized_classification}
\alias{spatialized_classification}
\title{Construct spatialized classification model.}
\usage{
spatialized_classification(training_data, response_variable,
  training_data_filter_type = "circular",
  training_data_filter_parameters = NULL, additional_variables = NULL,
  imbalance_correction = "upSample", nsamples = 500,
  model = "randomForestSRC", ntree = 1000, importance = FALSE,
  nsplit = 1, mtry = NULL, auto_varselect = TRUE, auto_ntree = TRUE,
  conservative = FALSE, error_rate_change_threshold = 0.001,
  cores = floor(detectCores()/2), do.trace = 0, verbose = FALSE)
}
\arguments{
\item{training_data}{List. Output list from ?extract_windows.}

\item{response_variable}{Character. Column name of the categorical variable to be used.}

\item{training_data_filter_type}{Character. Extracted windows are rectangular, by default, but they can be adjusted with this setting.  The default is "circular".}

\item{training_data_filter_parameters}{Vector. Parameters for use with various training_data_filter_types. See Details.}

\item{additional_variables}{Currently unsupported.  Will eventually allow for indices to be created.}

\item{imbalance_correction}{Character. Can be "none", "balanced", "upSample", or "downSample".  See Details. Default is "upSample".}

\item{nsamples}{Numeric. Number of samples to use with balanced correction.  Default is 500.}

\item{model}{Character. Classification algorithm to use.  Default is randomForestSRC. Other algorithms are not currently supported.}

\item{ntree}{Numeric. randomForestSRC only. Number of trees to use.  Default is 1000. See ?rfsrc.}

\item{importance}{Logical. randomForestSRC only. Calculate variable importance?  Default is FALSE.  Setting to TRUE can significantly increase the computation time and memory use. See ?rfsrc.}

\item{nsplit}{Non-negative integer value. randomForestSRC only. See ?rfsrc.}

\item{mtry}{Numeric. randomForestSRC only. Number of variables randomly selected as candidates for each node split. See Details and ?rfsrc.}

\item{auto_varselect}{Logical. If TRUE, will optimize the number of variables used in the final model using the maximal subtree algorithm.  Default is TRUE.}

\item{auto_ntree}{Logical. If TRUE, will optimze the number of trees used in the final model based on the error_rate_change_threshold setting.  Default is TRUE.}

\item{conservative}{Logical. Used with auto_varselect. See ?rfsrc. Default=FALSE.}

\item{error_rate_change_threshold}{Numeric. If the change in error rate is less than this amount, the model is deemed "finished" if auto_ntree=T.  Default is 0.001 (1% change).}

\item{cores}{Numeric. randomForestSRC only. How many cores to use in the construction of the model.  Default is half of the available cores (floor(detectCores()/2)).}

\item{do.trace}{Numeric. Currently unsupported.}

\item{verbose}{Logical.}
}
\description{
Construct spatialized classification model.
}
\details{
Constructs a classification model using the spatial-spectral data extracted from ?extract_windows. Currently, the model
uses randomForestSRC as the "engine".  The algorithm proceeds through several steps:
1) If the user wishes to apply a filter to the extracted windows (e.g. only use pixels within a circle around the central pixel),
the algorithm first pre-filters the data.  Currently, only a circular filter is supported (more will be added later), and the radius
of this circle is set based on training_data_filter_parameters (training_data_filter_parameters=0 will use only the central pixel, for instance),
or, if missing, will be set the smaller of the two window_dim divided by 2.  
2) Random Forests don't behave well with highly imbalanced datasets (more pixels belonging to one class than another), so we have included three
imbalancing approaches: "upSample" (default): the minority classes are sampled with replacement up to the size of the majority class, "downSample":
the majority classes are sampled without replacement to the size of the minority class, and "balanced": a predetermined sample size is set by
the "nsamples" parameter, and all classes with samples smaller than nsamples are upsampled, and all classes larger than nsamples are downsampled. 
We currently recommend using "upSample" for smaller training datasets, and "balanced" for much larger datasets.
3) The model is run using all variables not filtered, with the number of trees set to "ntree".  If auto_varselect==TRUE, mtry will be set 
by default to the number of variables ^ 4/5.  If not, it will set by default to number of variables ^ 1/2.
4) If auto_varselect=TRUE, the maximal subtree method (?max.subtree) will be used to select the variables needed in the model.  
Once this subset is determined, the model is rerun with the reduced variables set.
5) If auto_ntree=TRUE, the error rate of the model will be examined to determine what number of trees is needed to realize an error rate change
of less than the error_rate_change_threshold. The model is re-run with only this number of trees.  If the model can't reduce the number of trees,
a warning will be thrown.  The model should probably be re-run with ntree set to a higher number.
6) The final model is then returned to the user.

Key optimization settings: 
imbalance_correction = "balanced" and set a reasonable number of nsamples
importance = FALSE
auto_varselect = TRUE
auto_ntree = FALSE
cores = detectCores()
}
\examples{
# Load extracted 5x5 windows from a set of polygons.
data("extracted_training_polys")
 
# Create model:
spatialized_classification_model <- spatialized_classification(training_data=extracted_training_polys,
				response="class",training_data_filter_type="circular",model="randomForestSRC",importance=FALSE,
				cores=1,imbalance_correction="upSample",
				auto_varselect=TRUE,auto_ntree=TRUE)

import randomForestSRC caret parallel
}
\author{
Jonathan A. Greenberg (\email{spatial.tools@estarcion.net})
}

